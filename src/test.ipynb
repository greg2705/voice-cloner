{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whisper Streaming Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from whisper_online import FasterWhisperASR,OnlineASRProcessor,load_audio,load_audio_chunk\n",
    "import numpy as np\n",
    "import pyaudio\n",
    "import librosa\n",
    "\n",
    "language = \"en\"\n",
    "model_path = \"C:/Users/Greg/Documents/Job/PythonProject/ressources/Model/faster_whisper_v3\"\n",
    "\n",
    "# Loads and wrap whisper model\n",
    "asr = FasterWhisperASR(language, model_dir=model_path)\n",
    "\n",
    "## Set Options\n",
    "\n",
    "# Translate Task\n",
    "# asr.set_translate_task()\n",
    "\n",
    "# Vad option\n",
    "# asr.use_vad()\n",
    "\n",
    "# create processing object with default buffer trimming option\n",
    "online = OnlineASRProcessor(asr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Using basic audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Audio stream !\n",
      " The following is a conversation with Elon Musk. His fourth time on this, the Lex Friedman podcast I thought you were going to finish it. It's one of the greatest themes in all of film history. Yeah, that's great. So I was just thinking about the Roman Empire, as one does. There's that whole meme where... Well, guys, I was thinking about the Roman Empire at least once a day. And half the population is confused whether it's true or not. But more seriously, thinking about the wars going on in the world today, and as you know, war and military conquest has been a big part of Roman society and culture.\n",
      "Finishing Audio Stream !\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from whisper_online import FasterWhisperASR,OnlineASRProcessor,load_audio,load_audio_chunk\n",
    "import numpy as np\n",
    "import pyaudio\n",
    "import librosa\n",
    "\n",
    "language = \"en\"\n",
    "model_path = \"C:/Users/Greg/Documents/Job/PythonProject/ressources/Model/faster_whisper_turbo\"\n",
    "\n",
    "# Loads and wrap whisper model\n",
    "asr = FasterWhisperASR(language, model_dir=model_path)\n",
    "\n",
    "## Set Options\n",
    "\n",
    "# Translate Task\n",
    "# asr.set_translate_task()\n",
    "\n",
    "# Vad option\n",
    "# asr.use_vad()\n",
    "\n",
    "# create processing object with default buffer trimming option\n",
    "online = OnlineASRProcessor(asr)\n",
    "\n",
    "audio_path = \"audio/elo_musk_podcast.wav\"\n",
    "\n",
    "SAMPLING_RATE = 16000\n",
    "\n",
    "# Adjust it in function (espcially when streaming)\n",
    "\n",
    "# duration = len(load_audio(audio_path))/SAMPLING_RATE # Whole audio duration\n",
    "\n",
    "duration = 60  # One minute duration\n",
    "\n",
    "a = load_audio_chunk(audio_path,0,1)\n",
    "\n",
    "\n",
    "# warm up the asr because the very first transcribe take much more time than the other \n",
    "asr.transcribe(a)\n",
    "\n",
    "beg = 0\n",
    "start = time.time()-beg\n",
    "end = 0\n",
    "min_chunk = 1\n",
    "\n",
    "print(\"Starting Audio stream !\")\n",
    "while True :\n",
    "\n",
    "    now = time.time() - start\n",
    "    if now < end + min_chunk:\n",
    "        time.sleep(min_chunk+end-now)\n",
    "\n",
    "    end = time.time() - start\n",
    "    a = load_audio_chunk(audio_path,beg,end)\n",
    "    beg = end\n",
    "    online.insert_audio_chunk(a)\n",
    "    o = online.process_iter()\n",
    "\n",
    "    print(o[2],end=\"\",flush=True)\n",
    "    now = time.time() - start\n",
    "\n",
    "    if end >= duration:\n",
    "        break\n",
    "print()\n",
    "print(\"Finishing Audio Stream !\")\n",
    "o = online.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Using Streamed Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available audio devices:\n",
      "0: Mappeur de sons Microsoft - Input (max input channels: 2)\n",
      "1: Microphone (Logitech PRO X Gami (max input channels: 1)\n",
      "2: Microphone (Sonic Studio Virtua (max input channels: 2)\n",
      "3: Microphone (Logi C270 HD WebCam (max input channels: 1)\n",
      "4: Mappeur de sons Microsoft - Output (max input channels: 0)\n",
      "5: Haut-parleurs (Logitech PRO X G (max input channels: 0)\n",
      "6: PL2770QS (NVIDIA High Definitio (max input channels: 0)\n",
      "7: Haut-parleurs (Sonic Studio Vir (max input channels: 0)\n",
      "8: LC24RG50 (NVIDIA High Definitio (max input channels: 0)\n",
      "9: Realtek Digital Output (Realtek (max input channels: 0)\n",
      "10: Pilote de capture audio principal (max input channels: 2)\n",
      "11: Microphone (Logitech PRO X Gaming Headset) (max input channels: 1)\n",
      "12: Microphone (Sonic Studio Virtual Mixer) (max input channels: 2)\n",
      "13: Microphone (Logi C270 HD WebCam) (max input channels: 1)\n",
      "14: Périphérique audio principal (max input channels: 0)\n",
      "15: Haut-parleurs (Logitech PRO X Gaming Headset) (max input channels: 0)\n",
      "16: PL2770QS (NVIDIA High Definition Audio) (max input channels: 0)\n",
      "17: Haut-parleurs (Sonic Studio Virtual Mixer) (max input channels: 0)\n",
      "18: LC24RG50 (NVIDIA High Definition Audio) (max input channels: 0)\n",
      "19: Realtek Digital Output (Realtek USB Audio) (max input channels: 0)\n",
      "20: Haut-parleurs (Logitech PRO X Gaming Headset) (max input channels: 0)\n",
      "21: PL2770QS (NVIDIA High Definition Audio) (max input channels: 0)\n",
      "22: Haut-parleurs (Sonic Studio Virtual Mixer) (max input channels: 0)\n",
      "23: LC24RG50 (NVIDIA High Definition Audio) (max input channels: 0)\n",
      "24: Realtek Digital Output (Realtek USB Audio) (max input channels: 0)\n",
      "25: Microphone (Sonic Studio Virtual Mixer) (max input channels: 2)\n",
      "26: Microphone (Logi C270 HD WebCam) (max input channels: 1)\n",
      "27: Microphone (Logitech PRO X Gaming Headset) (max input channels: 1)\n",
      "28: Microphone (PRO X) (max input channels: 1)\n",
      "29: Haut-parleurs (PRO X) (max input channels: 0)\n",
      "30: Casque (Realtek USB Audio) (max input channels: 0)\n",
      "31: Haut-parleurs (Realtek USB Audio) (max input channels: 0)\n",
      "32: Interface SPDIF (Realtek USB Audio) (max input channels: 0)\n",
      "33: Entrée ligne (Realtek USB Audio) (max input channels: 2)\n",
      "34: Microphone (Realtek USB Audio) (max input channels: 2)\n",
      "35: Mixage stéréo (Realtek USB Audio) (max input channels: 2)\n",
      "36: Microphone (Logi C270 HD WebCam) (max input channels: 1)\n",
      "37: Speakers (SONICSTUDIOVAD Wave Speaker) (max input channels: 0)\n",
      "38: Microphone (SONICSTUDIOVAD Wave Speaker) (max input channels: 2)\n",
      "39: Output (NVIDIA High Definition Audio) (max input channels: 0)\n",
      "40: Output () (max input channels: 0)\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "\n",
    "# PyAudio configuration for capturing audio\n",
    "CHUNK = 1024  # Number of audio samples per frame\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 2  # Stereo input\n",
    "INPUT_RATE = 44100  # Typical system audio rate\n",
    "OUTPUT_RATE = 16000  # Required rate for the pipeline (16kHz)\n",
    "\n",
    "# Initialize PyAudio\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# List available audio input devices\n",
    "print(\"Available audio devices:\")\n",
    "for i in range(p.get_device_count()):\n",
    "    dev = p.get_device_info_by_index(i)\n",
    "    print(f\"{i}: {dev['name']} (max input channels: {dev['maxInputChannels']})\")\n",
    "\n",
    "## Choose yours\n",
    "\n",
    "index_stream_audio = 35\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-up finished\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno -9999] Unanticipated host error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 38\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarm-up finished\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m duration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m60\u001b[39m \u001b[38;5;66;03m# Duration in second\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m stream \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFORMAT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m                \u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCHANNELS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mINPUT_RATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m                \u001b[49m\u001b[43minput_device_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_stream_audio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m                \u001b[49m\u001b[43mframes_per_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mListening to system audio...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\Greg\\anaconda3\\envs\\whisper_streaming\\lib\\site-packages\\pyaudio\\__init__.py:639\u001b[0m, in \u001b[0;36mPyAudio.open\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    632\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Opens a new stream.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \n\u001b[0;32m    634\u001b[0m \u001b[38;5;124;03m    See constructor for :py:func:`PyAudio.Stream.__init__` for parameter\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;124;03m    :returns: A new :py:class:`PyAudio.Stream`\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 639\u001b[0m     stream \u001b[38;5;241m=\u001b[39m PyAudio\u001b[38;5;241m.\u001b[39mStream(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_streams\u001b[38;5;241m.\u001b[39madd(stream)\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stream\n",
      "File \u001b[1;32mc:\\Users\\Greg\\anaconda3\\envs\\whisper_streaming\\lib\\site-packages\\pyaudio\\__init__.py:441\u001b[0m, in \u001b[0;36mPyAudio.Stream.__init__\u001b[1;34m(self, PA_manager, rate, channels, format, input, output, input_device_index, output_device_index, frames_per_buffer, start, input_host_api_specific_stream_info, output_host_api_specific_stream_info, stream_callback)\u001b[0m\n\u001b[0;32m    438\u001b[0m     arguments[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstream_callback\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m stream_callback\n\u001b[0;32m    440\u001b[0m \u001b[38;5;66;03m# calling pa.open returns a stream object\u001b[39;00m\n\u001b[1;32m--> 441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream \u001b[38;5;241m=\u001b[39m pa\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39marguments)\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_latency \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream\u001b[38;5;241m.\u001b[39minputLatency\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_latency \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream\u001b[38;5;241m.\u001b[39moutputLatency\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno -9999] Unanticipated host error"
     ]
    }
   ],
   "source": [
    "def process_audio(audio_chunk, input_rate, output_rate, channels):\n",
    "    \"\"\"\n",
    "    Process audio to required format:\n",
    "    - Downsample to output_rate\n",
    "    - Convert to mono if necessary\n",
    "    \"\"\"\n",
    "    # Convert raw audio bytes to NumPy array\n",
    "    audio_data = np.frombuffer(audio_chunk, dtype=np.int16)\n",
    "    # Reshape stereo to separate channels\n",
    "    if channels == 2:\n",
    "        audio_data = audio_data.reshape(-1, 2)\n",
    "        audio_data = np.mean(audio_data, axis=1)  # Convert to mono by averaging\n",
    "    # Resample to 16kHz\n",
    "    audio_data = librosa.resample(audio_data.astype(np.float32), orig_sr=input_rate, target_sr=output_rate)\n",
    "    return audio_data\n",
    "\n",
    "\n",
    "audio_path = \"audio/elo_musk_podcast.wav\"\n",
    "\n",
    "SAMPLING_RATE = 16000\n",
    "\n",
    "# Adjust it in function (espcially when streaming)\n",
    "\n",
    "# duration = len(load_audio(audio_path))/SAMPLING_RATE # Whole audio duration\n",
    "\n",
    "duration = 60  # One minute duration\n",
    "\n",
    "a = load_audio_chunk(audio_path,0,1)\n",
    "\n",
    "\n",
    "# warm up the asr because the very first transcribe take much more time than the other \n",
    "asr.transcribe(a)\n",
    "\n",
    "print(\"Warm-up finished\")\n",
    "\n",
    "duration = 60 # Duration in second\n",
    "\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=INPUT_RATE,\n",
    "                input=True,\n",
    "                input_device_index=index_stream_audio,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"Listening to system audio...\")\n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "min_chunk = 1\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        now = time.time()\n",
    "\n",
    "        # Capture audio chunk\n",
    "        audio_chunk = stream.read(CHUNK, exception_on_overflow=False)\n",
    "\n",
    "        # Process audio to 16kHz mono\n",
    "        processed_audio = process_audio(audio_chunk, INPUT_RATE, OUTPUT_RATE, CHANNELS)\n",
    "        \n",
    "        print(pro)\n",
    "        # online.insert_audio_chunk(a)\n",
    "        # o = online.process_iter()\n",
    "        # print(o,end=\"  \",flush=True)\n",
    "\n",
    "        # if(time.time()-start >duration+2):\n",
    "        #     print(\"\\n Duration Complete\")\n",
    "        #     break\n",
    "        \n",
    "        \n",
    "        # if now - time.time() <  min_chunk:\n",
    "        #     time.sleep(min_chunk)\n",
    "        \n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopped by user.\")\n",
    "finally:\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Using Server "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized and warmed up successfully\n",
      " The following is a conversation with Elon Musk. his fourth time on this, the Lex Friedman Podcast. I thought you were going to finish it.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import librosa\n",
    "import time\n",
    "import scipy.io.wavfile as wav\n",
    "import json\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    "# URL of the FastAPI application\n",
    "url = \"http://127.0.0.1:8000\"\n",
    "\n",
    "\n",
    "# Function to read and resample audio chunk\n",
    "def read_audio_chunk(file_path, start, end, sr=16000):\n",
    "    # Calculate the start and end in samples for the desired sample rate\n",
    "    start_sample = int(start * sr)\n",
    "    end_sample = int(end * sr)\n",
    "    duration = end - start\n",
    "\n",
    "    # Use soundfile to load only the required segment\n",
    "    audio, orig_sr = sf.read(file_path, start=start_sample, stop=end_sample, dtype='float32')\n",
    "\n",
    "    # Convert to mono if it's multi-channel\n",
    "    if audio.ndim > 1:\n",
    "        audio = np.mean(audio, axis=1)\n",
    "\n",
    "    # Resample only if necessary\n",
    "    if orig_sr != sr:\n",
    "        audio = librosa.resample(audio, orig_sr=orig_sr, target_sr=sr)\n",
    "\n",
    "    return audio\n",
    "\n",
    "# Path to the audio file\n",
    "audio_path = \"audio/elo_musk_podcast.wav\"\n",
    "\n",
    "# Total duration of the audio file\n",
    "total_duration = 60  # 60 seconds\n",
    "\n",
    "# Initialize the model\n",
    "response = requests.post(f\"{url}/init/\")\n",
    "print(response.json()[\"message\"])\n",
    "\n",
    "\n",
    "# Start sending chunks\n",
    "start_time = time.time()\n",
    "beg = 0\n",
    "end = 0\n",
    "min_chunk = 2  # Minimum chunk duration in seconds\n",
    "\n",
    "while True:\n",
    "    now = time.time() - start_time\n",
    "    if now < end + min_chunk:\n",
    "        time.sleep(min_chunk + end - now)\n",
    "\n",
    "    end = time.time() - start_time\n",
    "\n",
    "\n",
    "    audio_chunk = read_audio_chunk(audio_path, beg, end)\n",
    "\n",
    "    payload = {\n",
    "    \"audio_array\": audio_chunk.tolist(),\n",
    "    \"sample_rate\": 16000\n",
    "        }\n",
    "\n",
    "    # Send the audio chunk to the FastAPI application\n",
    "    response = requests.post(f\"{url}/upload_chunk/\",json=payload)\n",
    "    \n",
    "\n",
    "    # Print the transcription\n",
    "    print(response.json()[\"transcription\"],end=\"\",flush=True)\n",
    "    beg = end\n",
    "\n",
    "    if end >= total_duration:\n",
    "        break\n",
    "\n",
    "# Finish processing and get the final transcription\n",
    "response = requests.post(f\"{url}/finish/\")\n",
    "print(response.json()[\"final_transcription\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Connected to server at localhost:8000\n",
      "INFO:__main__:Streaming audio... Press Ctrl+C to stop.\n",
      "INFO:__main__:Received transcription: 0 2120  Thank you.\n",
      "\n",
      "INFO:__main__:Received transcription: 6700 6760  Thank you.\n",
      "\n",
      "INFO:__main__:Received transcription: 30260 30740  you\n",
      "\n",
      "INFO:__main__:Received transcription: 31840 33280  Thank you.\n",
      "\n",
      "INFO:__main__:Received transcription: 36040 37320  Thank you.\n",
      "\n",
      "INFO:__main__:Received transcription: 39840 41120  Thank you.\n",
      "\n",
      "ERROR:__main__:Error receiving server response: [WinError 10054] Une connexion existante a dû être fermée par l’hôte distant\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "from scipy.signal import resample\n",
    "import logging\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Parameters\n",
    "host = \"localhost\"  # Set the server host\n",
    "port = 8000       # Set the server port\n",
    "sampling_rate = 16000  # Required sampling rate by the server\n",
    "chunk_duration = 1.0  # Duration of each audio chunk in seconds (1 second)\n",
    "chunk_size = int(sampling_rate * chunk_duration)  # Number of samples per chunk\n",
    "\n",
    "def stream_live_audio_with_response(host, port, sampling_rate, chunk_size):\n",
    "    \"\"\"\n",
    "    Stream live audio from the computer's output to the server and print transcriptions.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Connect to the server\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "            s.connect((host, port))\n",
    "            logger.info(f\"Connected to server at {host}:{port}\")\n",
    "\n",
    "            def callback(indata, outdata, frames, time, status):\n",
    "                \"\"\"\n",
    "                Audio callback to process, resample, and send audio data.\n",
    "                \"\"\"\n",
    "                if status:\n",
    "                    logger.warning(f\"Audio status: {status}\")\n",
    "                \n",
    "                # If audio has multiple channels, convert to mono\n",
    "                if indata.shape[1] > 1:  \n",
    "                    indata = np.mean(indata, axis=1, keepdims=True)\n",
    "\n",
    "                # Resample to 16 kHz if necessary\n",
    "                current_rate = sd.query_devices(sd.default.device[0], \"input\")[\"default_samplerate\"]\n",
    "                if current_rate != sampling_rate:\n",
    "                    num_samples = int(chunk_size)  # Desired number of samples for 16 kHz\n",
    "                    indata = resample(indata, num_samples, axis=0)\n",
    "\n",
    "                try:\n",
    "                    s.sendall(indata.astype(np.int16).tobytes())  # Convert to 16-bit PCM\n",
    "                except BrokenPipeError:\n",
    "                    logger.error(\"Connection to server lost.\")\n",
    "                    raise\n",
    "\n",
    "            # Open audio stream\n",
    "            with sd.Stream(\n",
    "                samplerate=sampling_rate,  # Set target sample rate\n",
    "                channels=1,                # Force mono audio\n",
    "                dtype=\"float32\",           # Use float32 for processing before conversion\n",
    "                callback=callback,\n",
    "                blocksize=chunk_size       # Set chunk size\n",
    "            ):\n",
    "                logger.info(\"Streaming audio... Press Ctrl+C to stop.\")\n",
    "                \n",
    "                # Continuously receive server responses\n",
    "                while True:\n",
    "                    try:\n",
    "                        response = s.recv(1024)  # Adjust buffer size as needed\n",
    "                        if response:\n",
    "                            logger.info(f\"Received transcription: {response.decode('utf-8')}\")\n",
    "                    except socket.timeout:\n",
    "                        pass  # No response yet; continue streaming\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Error receiving server response: {e}\")\n",
    "                        break\n",
    "\n",
    "    except ConnectionError as e:\n",
    "        logger.error(f\"Failed to connect to the server: {e}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {e}\")\n",
    "\n",
    "# Call the function to start streaming\n",
    "stream_live_audio_with_response(host, port, sampling_rate, chunk_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import wave\n",
    "import logging\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Parameters\n",
    "host = \"localhost\"  # Set the server host\n",
    "port = 43007        # Set the server port\n",
    "file_path = \"path/to/audio.wav\"  # Path to the WAV file to stream\n",
    "chunk_size = 32000  # Audio chunk size in bytes\n",
    "\n",
    "def convert_to_mono_16khz(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Convert a WAV file to mono and 16 kHz if necessary.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Processing {input_path} for conversion to mono and 16 kHz...\")\n",
    "    try:\n",
    "        audio = AudioSegment.from_file(input_path)\n",
    "        if audio.frame_rate != 16000 or audio.channels != 1:\n",
    "            audio = audio.set_frame_rate(16000).set_channels(1)\n",
    "            audio.export(output_path, format=\"wav\")\n",
    "            logger.info(f\"File converted and saved to {output_path}\")\n",
    "            return output_path\n",
    "        else:\n",
    "            logger.info(\"File is already in the correct format.\")\n",
    "            return input_path\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during conversion: {e}\")\n",
    "        raise\n",
    "\n",
    "# Function to stream a WAV file and receive transcriptions\n",
    "def stream_wav_and_receive(host, port, file_path, chunk_size):\n",
    "    # Ensure the file is in mono and 16 kHz\n",
    "    try:\n",
    "        processed_file = \"processed_audio.wav\"\n",
    "        file_path = convert_to_mono_16khz(file_path, processed_file)\n",
    "    except Exception as e:\n",
    "        logger.error(\"Unable to process audio file.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Open the WAV file\n",
    "        with wave.open(file_path, \"rb\") as wf:\n",
    "            # Validate WAV file properties\n",
    "            if wf.getsampwidth() != 2 or wf.getnchannels() != 1 or wf.getframerate() != 16000:\n",
    "                logger.error(\"The WAV file must be 16-bit PCM, mono, with a 16kHz sampling rate.\")\n",
    "                return\n",
    "\n",
    "            # Connect to the server\n",
    "            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "                s.connect((host, port))\n",
    "                logger.info(f\"Connected to server at {host}:{port}\")\n",
    "\n",
    "                # Stream audio in chunks and listen for responses\n",
    "                data = wf.readframes(chunk_size // 2)\n",
    "                s.settimeout(1)  # Set timeout for receiving responses\n",
    "                try:\n",
    "                    while data:\n",
    "                        # Send audio chunk\n",
    "                        s.sendall(data)\n",
    "                        logger.info(f\"Sent {len(data)} bytes\")\n",
    "                        data = wf.readframes(chunk_size // 2)\n",
    "\n",
    "                        # Receive transcription from server\n",
    "                        try:\n",
    "                            response = s.recv(1024)  # Adjust buffer size as needed\n",
    "                            if response:\n",
    "                                logger.info(f\"Received transcription: {response.decode('utf-8')}\")\n",
    "                        except socket.timeout:\n",
    "                            pass  # No response yet; continue sending audio\n",
    "\n",
    "                    logger.info(\"Finished streaming the audio file.\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error during streaming: {e}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"The file {file_path} was not found.\")\n",
    "    except ConnectionError as e:\n",
    "        logger.error(f\"Failed to connect to the server: {e}\")\n",
    "    except wave.Error as e:\n",
    "        logger.error(f\"Error reading WAV file: {e}\")\n",
    "\n",
    "# Call the function\n",
    "stream_wav_and_receive(host, port, file_path, chunk_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper_streaming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
