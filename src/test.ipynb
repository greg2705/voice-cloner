{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whisper Streaming Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from whisper_online import FasterWhisperASR,OnlineASRProcessor,load_audio,load_audio_chunk\n",
    "import numpy as np\n",
    "import pyaudio\n",
    "import librosa\n",
    "\n",
    "language = \"en\"\n",
    "model_path = \"C:/Users/Greg/Documents/Job/PythonProject/ressources/Model/faster_whisper_v3\"\n",
    "\n",
    "# Loads and wrap whisper model\n",
    "asr = FasterWhisperASR(language, model_dir=model_path)\n",
    "\n",
    "## Set Options\n",
    "\n",
    "# Translate Task\n",
    "# asr.set_translate_task()\n",
    "\n",
    "# Vad option\n",
    "# asr.use_vad()\n",
    "\n",
    "# create processing object with default buffer trimming option\n",
    "online = OnlineASRProcessor(asr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Using basic audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from whisper_online import FasterWhisperASR,OnlineASRProcessor,load_audio,load_audio_chunk\n",
    "import numpy as np\n",
    "import pyaudio\n",
    "import librosa\n",
    "\n",
    "language = \"en\"\n",
    "model_path = \"C:/Users/Greg/Documents/Job/PythonProject/ressources/Model/faster_whisper_turbo\"\n",
    "\n",
    "# Loads and wrap whisper model\n",
    "asr = FasterWhisperASR(language, model_dir=model_path)\n",
    "\n",
    "## Set Options\n",
    "\n",
    "# Translate Task\n",
    "# asr.set_translate_task()\n",
    "\n",
    "# Vad option\n",
    "# asr.use_vad()\n",
    "\n",
    "# create processing object with default buffer trimming option\n",
    "online = OnlineASRProcessor(asr)\n",
    "\n",
    "audio_path = \"audio/elo_musk_podcast.wav\"\n",
    "\n",
    "SAMPLING_RATE = 16000\n",
    "\n",
    "# Adjust it in function (espcially when streaming)\n",
    "\n",
    "# duration = len(load_audio(audio_path))/SAMPLING_RATE # Whole audio duration\n",
    "\n",
    "duration = 60  # One minute duration\n",
    "\n",
    "a = load_audio_chunk(audio_path,0,1)\n",
    "\n",
    "\n",
    "# warm up the asr because the very first transcribe take much more time than the other \n",
    "asr.transcribe(a)\n",
    "\n",
    "beg = 0\n",
    "start = time.time()-beg\n",
    "end = 0\n",
    "min_chunk = 1\n",
    "\n",
    "print(\"Starting Audio stream !\")\n",
    "while True :\n",
    "\n",
    "    now = time.time() - start\n",
    "    if now < end + min_chunk:\n",
    "        time.sleep(min_chunk+end-now)\n",
    "\n",
    "    end = time.time() - start\n",
    "    a = load_audio_chunk(audio_path,beg,end)\n",
    "    beg = end\n",
    "    online.insert_audio_chunk(a)\n",
    "    o = online.process_iter()\n",
    "\n",
    "    print(o[2],end=\"\",flush=True)\n",
    "    now = time.time() - start\n",
    "\n",
    "    if end >= duration:\n",
    "        break\n",
    "print()\n",
    "print(\"Finishing Audio Stream !\")\n",
    "o = online.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Using Streamed Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "\n",
    "# PyAudio configuration for capturing audio\n",
    "CHUNK = 1024  # Number of audio samples per frame\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 2  # Stereo input\n",
    "INPUT_RATE = 44100  # Typical system audio rate\n",
    "OUTPUT_RATE = 16000  # Required rate for the pipeline (16kHz)\n",
    "\n",
    "# Initialize PyAudio\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# List available audio input devices\n",
    "print(\"Available audio devices:\")\n",
    "for i in range(p.get_device_count()):\n",
    "    dev = p.get_device_info_by_index(i)\n",
    "    print(f\"{i}: {dev['name']} (max input channels: {dev['maxInputChannels']})\")\n",
    "\n",
    "## Choose yours\n",
    "\n",
    "index_stream_audio = 35\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio(audio_chunk, input_rate, output_rate, channels):\n",
    "    \"\"\"\n",
    "    Process audio to required format:\n",
    "    - Downsample to output_rate\n",
    "    - Convert to mono if necessary\n",
    "    \"\"\"\n",
    "    # Convert raw audio bytes to NumPy array\n",
    "    audio_data = np.frombuffer(audio_chunk, dtype=np.int16)\n",
    "    # Reshape stereo to separate channels\n",
    "    if channels == 2:\n",
    "        audio_data = audio_data.reshape(-1, 2)\n",
    "        audio_data = np.mean(audio_data, axis=1)  # Convert to mono by averaging\n",
    "    # Resample to 16kHz\n",
    "    audio_data = librosa.resample(audio_data.astype(np.float32), orig_sr=input_rate, target_sr=output_rate)\n",
    "    return audio_data\n",
    "\n",
    "\n",
    "audio_path = \"audio/elo_musk_podcast.wav\"\n",
    "\n",
    "SAMPLING_RATE = 16000\n",
    "\n",
    "# Adjust it in function (espcially when streaming)\n",
    "\n",
    "# duration = len(load_audio(audio_path))/SAMPLING_RATE # Whole audio duration\n",
    "\n",
    "duration = 60  # One minute duration\n",
    "\n",
    "a = load_audio_chunk(audio_path,0,1)\n",
    "\n",
    "\n",
    "# warm up the asr because the very first transcribe take much more time than the other \n",
    "asr.transcribe(a)\n",
    "\n",
    "print(\"Warm-up finished\")\n",
    "\n",
    "duration = 60 # Duration in second\n",
    "\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=INPUT_RATE,\n",
    "                input=True,\n",
    "                input_device_index=index_stream_audio,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"Listening to system audio...\")\n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "min_chunk = 1\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        now = time.time()\n",
    "\n",
    "        # Capture audio chunk\n",
    "        audio_chunk = stream.read(CHUNK, exception_on_overflow=False)\n",
    "\n",
    "        # Process audio to 16kHz mono\n",
    "        processed_audio = process_audio(audio_chunk, INPUT_RATE, OUTPUT_RATE, CHANNELS)\n",
    "        \n",
    "        print(pro)\n",
    "        # online.insert_audio_chunk(a)\n",
    "        # o = online.process_iter()\n",
    "        # print(o,end=\"  \",flush=True)\n",
    "\n",
    "        # if(time.time()-start >duration+2):\n",
    "        #     print(\"\\n Duration Complete\")\n",
    "        #     break\n",
    "        \n",
    "        \n",
    "        # if now - time.time() <  min_chunk:\n",
    "        #     time.sleep(min_chunk)\n",
    "        \n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopped by user.\")\n",
    "finally:\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Using Server "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import librosa\n",
    "import time\n",
    "import scipy.io.wavfile as wav\n",
    "import json\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    "# URL of the FastAPI application\n",
    "url = \"http://127.0.0.1:8000\"\n",
    "\n",
    "\n",
    "# Function to read and resample audio chunk\n",
    "def read_audio_chunk(file_path, start, end, sr=16000):\n",
    "    # Calculate the start and end in samples for the desired sample rate\n",
    "    start_sample = int(start * sr)\n",
    "    end_sample = int(end * sr)\n",
    "    duration = end - start\n",
    "\n",
    "    # Use soundfile to load only the required segment\n",
    "    audio, orig_sr = sf.read(file_path, start=start_sample, stop=end_sample, dtype='float32')\n",
    "\n",
    "    # Convert to mono if it's multi-channel\n",
    "    if audio.ndim > 1:\n",
    "        audio = np.mean(audio, axis=1)\n",
    "\n",
    "    # Resample only if necessary\n",
    "    if orig_sr != sr:\n",
    "        audio = librosa.resample(audio, orig_sr=orig_sr, target_sr=sr)\n",
    "\n",
    "    return audio\n",
    "\n",
    "# Path to the audio file\n",
    "audio_path = \"audio/elo_musk_podcast.wav\"\n",
    "\n",
    "# Total duration of the audio file\n",
    "total_duration = 60  # 60 seconds\n",
    "\n",
    "# Initialize the model\n",
    "response = requests.post(f\"{url}/init/\")\n",
    "print(response.json()[\"message\"])\n",
    "\n",
    "\n",
    "# Start sending chunks\n",
    "start_time = time.time()\n",
    "beg = 0\n",
    "end = 0\n",
    "min_chunk = 2  # Minimum chunk duration in seconds\n",
    "\n",
    "while True:\n",
    "    now = time.time() - start_time\n",
    "    if now < end + min_chunk:\n",
    "        time.sleep(min_chunk + end - now)\n",
    "\n",
    "    end = time.time() - start_time\n",
    "\n",
    "\n",
    "    audio_chunk = read_audio_chunk(audio_path, beg, end)\n",
    "\n",
    "    payload = {\n",
    "    \"audio_array\": audio_chunk.tolist(),\n",
    "    \"sample_rate\": 16000\n",
    "        }\n",
    "\n",
    "    # Send the audio chunk to the FastAPI application\n",
    "    response = requests.post(f\"{url}/upload_chunk/\",json=payload)\n",
    "    \n",
    "\n",
    "    # Print the transcription\n",
    "    print(response.json()[\"transcription\"],end=\"\",flush=True)\n",
    "    beg = end\n",
    "\n",
    "    if end >= total_duration:\n",
    "        break\n",
    "\n",
    "# Finish processing and get the final transcription\n",
    "response = requests.post(f\"{url}/finish/\")\n",
    "print(response.json()[\"final_transcription\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "from scipy.signal import resample\n",
    "import logging\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Parameters\n",
    "host = \"localhost\"  # Set the server host\n",
    "port = 8000       # Set the server port\n",
    "sampling_rate = 16000  # Required sampling rate by the server\n",
    "chunk_duration = 1.0  # Duration of each audio chunk in seconds (1 second)\n",
    "chunk_size = int(sampling_rate * chunk_duration)  # Number of samples per chunk\n",
    "\n",
    "def stream_live_audio_with_response(host, port, sampling_rate, chunk_size):\n",
    "    \"\"\"\n",
    "    Stream live audio from the computer's output to the server and print transcriptions.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Connect to the server\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "            s.connect((host, port))\n",
    "            logger.info(f\"Connected to server at {host}:{port}\")\n",
    "\n",
    "            def callback(indata, outdata, frames, time, status):\n",
    "                \"\"\"\n",
    "                Audio callback to process, resample, and send audio data.\n",
    "                \"\"\"\n",
    "                if status:\n",
    "                    logger.warning(f\"Audio status: {status}\")\n",
    "                \n",
    "                # If audio has multiple channels, convert to mono\n",
    "                if indata.shape[1] > 1:  \n",
    "                    indata = np.mean(indata, axis=1, keepdims=True)\n",
    "\n",
    "                # Resample to 16 kHz if necessary\n",
    "                current_rate = sd.query_devices(sd.default.device[0], \"input\")[\"default_samplerate\"]\n",
    "                if current_rate != sampling_rate:\n",
    "                    num_samples = int(chunk_size)  # Desired number of samples for 16 kHz\n",
    "                    indata = resample(indata, num_samples, axis=0)\n",
    "\n",
    "                try:\n",
    "                    s.sendall(indata.astype(np.int16).tobytes())  # Convert to 16-bit PCM\n",
    "                except BrokenPipeError:\n",
    "                    logger.error(\"Connection to server lost.\")\n",
    "                    raise\n",
    "\n",
    "            # Open audio stream\n",
    "            with sd.Stream(\n",
    "                samplerate=sampling_rate,  # Set target sample rate\n",
    "                channels=1,                # Force mono audio\n",
    "                dtype=\"float32\",           # Use float32 for processing before conversion\n",
    "                callback=callback,\n",
    "                blocksize=chunk_size       # Set chunk size\n",
    "            ):\n",
    "                logger.info(\"Streaming audio... Press Ctrl+C to stop.\")\n",
    "                \n",
    "                # Continuously receive server responses\n",
    "                while True:\n",
    "                    try:\n",
    "                        response = s.recv(1024)  # Adjust buffer size as needed\n",
    "                        if response:\n",
    "                            logger.info(f\"Received transcription: {response.decode('utf-8')}\")\n",
    "                    except socket.timeout:\n",
    "                        pass  # No response yet; continue streaming\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Error receiving server response: {e}\")\n",
    "                        break\n",
    "\n",
    "    except ConnectionError as e:\n",
    "        logger.error(f\"Failed to connect to the server: {e}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {e}\")\n",
    "\n",
    "# Call the function to start streaming\n",
    "stream_live_audio_with_response(host, port, sampling_rate, chunk_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import wave\n",
    "import logging\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Parameters\n",
    "host = \"localhost\"  # Set the server host\n",
    "port = 43007        # Set the server port\n",
    "file_path = \"path/to/audio.wav\"  # Path to the WAV file to stream\n",
    "chunk_size = 32000  # Audio chunk size in bytes\n",
    "\n",
    "def convert_to_mono_16khz(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Convert a WAV file to mono and 16 kHz if necessary.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Processing {input_path} for conversion to mono and 16 kHz...\")\n",
    "    try:\n",
    "        audio = AudioSegment.from_file(input_path)\n",
    "        if audio.frame_rate != 16000 or audio.channels != 1:\n",
    "            audio = audio.set_frame_rate(16000).set_channels(1)\n",
    "            audio.export(output_path, format=\"wav\")\n",
    "            logger.info(f\"File converted and saved to {output_path}\")\n",
    "            return output_path\n",
    "        else:\n",
    "            logger.info(\"File is already in the correct format.\")\n",
    "            return input_path\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during conversion: {e}\")\n",
    "        raise\n",
    "\n",
    "# Function to stream a WAV file and receive transcriptions\n",
    "def stream_wav_and_receive(host, port, file_path, chunk_size):\n",
    "    # Ensure the file is in mono and 16 kHz\n",
    "    try:\n",
    "        processed_file = \"processed_audio.wav\"\n",
    "        file_path = convert_to_mono_16khz(file_path, processed_file)\n",
    "    except Exception as e:\n",
    "        logger.error(\"Unable to process audio file.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Open the WAV file\n",
    "        with wave.open(file_path, \"rb\") as wf:\n",
    "            # Validate WAV file properties\n",
    "            if wf.getsampwidth() != 2 or wf.getnchannels() != 1 or wf.getframerate() != 16000:\n",
    "                logger.error(\"The WAV file must be 16-bit PCM, mono, with a 16kHz sampling rate.\")\n",
    "                return\n",
    "\n",
    "            # Connect to the server\n",
    "            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "                s.connect((host, port))\n",
    "                logger.info(f\"Connected to server at {host}:{port}\")\n",
    "\n",
    "                # Stream audio in chunks and listen for responses\n",
    "                data = wf.readframes(chunk_size // 2)\n",
    "                s.settimeout(1)  # Set timeout for receiving responses\n",
    "                try:\n",
    "                    while data:\n",
    "                        # Send audio chunk\n",
    "                        s.sendall(data)\n",
    "                        logger.info(f\"Sent {len(data)} bytes\")\n",
    "                        data = wf.readframes(chunk_size // 2)\n",
    "\n",
    "                        # Receive transcription from server\n",
    "                        try:\n",
    "                            response = s.recv(1024)  # Adjust buffer size as needed\n",
    "                            if response:\n",
    "                                logger.info(f\"Received transcription: {response.decode('utf-8')}\")\n",
    "                        except socket.timeout:\n",
    "                            pass  # No response yet; continue sending audio\n",
    "\n",
    "                    logger.info(\"Finished streaming the audio file.\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error during streaming: {e}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"The file {file_path} was not found.\")\n",
    "    except ConnectionError as e:\n",
    "        logger.error(f\"Failed to connect to the server: {e}\")\n",
    "    except wave.Error as e:\n",
    "        logger.error(f\"Error reading WAV file: {e}\")\n",
    "\n",
    "# Call the function\n",
    "stream_wav_and_receive(host, port, file_path, chunk_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Processing audio/elo_musk_podcast.wav for conversion to mono and 16 kHz...\n",
      "INFO:__main__:File converted and saved to processed_audio.wav\n",
      "INFO:__main__:Connected to server at 127.0.0.1:8000\n",
      "INFO:__main__: The following is a\n",
      "INFO:__main__: conversation with Elon Musk.\n",
      "INFO:__main__: his fourth time on this\n",
      "INFO:__main__: The Lex Friedman Podcast.\n",
      "INFO:__main__: I thought you were going to finish it.\n",
      "INFO:__main__: It's one of the greatest\n",
      "INFO:__main__: themes in all film history.\n",
      "INFO:__main__: Yeah, it's great.\n",
      "INFO:__main__: So I was just thinking\n",
      "INFO:__main__: about the Roman Empire\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 91\u001b[0m\n\u001b[0;32m     88\u001b[0m nest_asyncio\u001b[38;5;241m.\u001b[39mapply()\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Call the function\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream_wav_and_receive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Greg\\anaconda3\\envs\\whisper_streaming\\lib\\site-packages\\nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[1;32mc:\\Users\\Greg\\anaconda3\\envs\\whisper_streaming\\lib\\site-packages\\nest_asyncio.py:92\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m     90\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Greg\\anaconda3\\envs\\whisper_streaming\\lib\\site-packages\\nest_asyncio.py:115\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    108\u001b[0m     heappop(scheduled)\n\u001b[0;32m    110\u001b[0m timeout \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[0;32m    113\u001b[0m         scheduled[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_when \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime(), \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 115\u001b[0m event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_events(event_list)\n\u001b[0;32m    118\u001b[0m end_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clock_resolution\n",
      "File \u001b[1;32mc:\\Users\\Greg\\anaconda3\\envs\\whisper_streaming\\lib\\selectors.py:324\u001b[0m, in \u001b[0;36mSelectSelector.select\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    322\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 324\u001b[0m     r, w, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_readers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_writers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "File \u001b[1;32mc:\\Users\\Greg\\anaconda3\\envs\\whisper_streaming\\lib\\selectors.py:315\u001b[0m, in \u001b[0;36mSelectSelector._select\u001b[1;34m(self, r, w, _, timeout)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_select\u001b[39m(\u001b[38;5;28mself\u001b[39m, r, w, _, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 315\u001b[0m     r, w, x \u001b[38;5;241m=\u001b[39m \u001b[43mselect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r, w \u001b[38;5;241m+\u001b[39m x, []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import websockets\n",
    "import wave\n",
    "import logging\n",
    "from pydub import AudioSegment\n",
    "import nest_asyncio\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Parameters\n",
    "host = \"127.0.0.1\"  # Set the server URL\n",
    "port = 8000        # Set the server port\n",
    "file_path = \"audio/elo_musk_podcast.wav\"  # Path to the WAV file to stream\n",
    "chunk_size = 32000  # Audio chunk size in bytes\n",
    "\n",
    "def convert_to_mono_16khz(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Convert a WAV file to mono and 16 kHz if necessary.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Processing {input_path} for conversion to mono and 16 kHz...\")\n",
    "    try:\n",
    "        audio = AudioSegment.from_file(input_path)\n",
    "        if audio.frame_rate != 16000 or audio.channels != 1:\n",
    "            audio = audio.set_frame_rate(16000).set_channels(1)\n",
    "            audio.export(output_path, format=\"wav\")\n",
    "            logger.info(f\"File converted and saved to {output_path}\")\n",
    "            return output_path\n",
    "        else:\n",
    "            logger.info(\"File is already in the correct format.\")\n",
    "            return input_path\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during conversion: {e}\")\n",
    "        raise\n",
    "\n",
    "async def stream_wav_and_receive(host, port, file_path, chunk_size):\n",
    "    # Ensure the file is in mono and 16 kHz\n",
    "    try:\n",
    "        processed_file = \"processed_audio.wav\"\n",
    "        file_path = convert_to_mono_16khz(file_path, processed_file)\n",
    "    except Exception as e:\n",
    "        logger.error(\"Unable to process audio file.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Open the WAV file\n",
    "        with wave.open(file_path, \"rb\") as wf:\n",
    "            # Validate WAV file properties\n",
    "            if wf.getsampwidth() != 2 or wf.getnchannels() != 1 or wf.getframerate() != 16000:\n",
    "                logger.error(\"The WAV file must be 16-bit PCM, mono, with a 16kHz sampling rate.\")\n",
    "                return\n",
    "\n",
    "            # Connect to the server\n",
    "            async with websockets.connect(f\"ws://{host}:{port}/ws\") as websocket:\n",
    "                logger.info(f\"Connected to server at {host}:{port}\")\n",
    "\n",
    "                # Stream audio in chunks and listen for responses\n",
    "                data = wf.readframes(chunk_size // 2)\n",
    "                while data:\n",
    "                    # Send audio chunk\n",
    "                    await websocket.send(data)\n",
    "                    # logger.info(f\"Sent {len(data)} bytes\")\n",
    "                    data = wf.readframes(chunk_size // 2)\n",
    "\n",
    "                    # Receive transcription from server\n",
    "                    try:\n",
    "                        \n",
    "                        response = await websocket.recv()\n",
    "                        \n",
    "                        if response:\n",
    "                            # logger.info(f\"Received transcription: {response}\")\n",
    "                            logger.info(f\"{response}\")\n",
    "                    except websockets.exceptions.ConnectionClosed:\n",
    "                        logger.info(\"WebSocket connection closed\")\n",
    "                        break\n",
    "\n",
    "                logger.info(\"Finished streaming the audio file.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"The file {file_path} was not found.\")\n",
    "    except ConnectionError as e:\n",
    "        logger.error(f\"Failed to connect to the server: {e}\")\n",
    "    except wave.Error as e:\n",
    "        logger.error(f\"Error reading WAV file: {e}\")\n",
    "\n",
    "# Apply nest_asyncio patch\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Call the function\n",
    "asyncio.run(stream_wav_and_receive(host, port, file_path, chunk_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper_streaming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
